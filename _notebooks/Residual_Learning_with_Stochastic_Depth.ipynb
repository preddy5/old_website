{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Learning and Stochastic Depth\n",
    "\n",
    "Residual networks are famed for receiving first place in latest ILSVRC image classification.\n",
    "\n",
    "They are able to achieve a start of the art performance in image classification tasks beating previous VGG net\n",
    "Stochastic Depth is a ridiculously simple idea which can help in training the network even if the maximum depth is in order of 1000s.(http://arxiv.org/pdf/1603.09382v2.pdf). Total Code is available at https://github.com/pradyu1993/Residual-Learning-and-Stochastic-Depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usual Importing\n",
    "\n",
    "Here I am specifically using theano instead of tensorflow because for some reason tensorflow performance is way less than theano for this code during initial testing and tensorflow occupies whole vram while compiling the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "os.environ['THEANO_FLAGS']='mode=FAST_RUN,device=gpu0,floatX=float32,optimizer=None'\n",
    "\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import Callback, LearningRateScheduler\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "\n",
    "from resnet import bn_relu_conv, conv_bn_relu, residual_block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Specific constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "learning_rate = 0.1\n",
    "momentum = 0.9\n",
    "img_rows, img_cols = 32, 32\n",
    "img_channels = 3\n",
    "nb_epochs = 400\n",
    "batch_size = 300\n",
    "nb_classes = 10\n",
    "pL = 0.5\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# data\n",
    "(X_train, Y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train = X_train.astype('float32')\n",
    "img_gen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    horizontal_flip=True)\n",
    "img_gen.fit(X_train)\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Blocks of Whole Network\n",
    "\n",
    "\n",
    "<img src=\"http://i0.wp.com/deliprao.com/wp-content/uploads/2016/04/Screen-Shot-2016-04-01-at-1.33.56-PM.png\">\n",
    "\n",
    "The lamdba function in _shortcut function is what makes the network **stochastic**. Effectively it is a implementation of the the picture shown above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _bottleneck(input, nb_filters, init_subsample=(1, 1)):\n",
    "    conv_1_1 = bn_relu_conv(input, nb_filters, 3, 3, W_regularizer=l2(weight_decay), subsample=init_subsample)\n",
    "    conv_3_3 = bn_relu_conv(conv_1_1, nb_filters, 3, 3, W_regularizer=l2(weight_decay))\n",
    "    return _shortcut(input, conv_3_3)\n",
    "\n",
    "    \n",
    "def _shortcut(input, residual):\n",
    "    stride_width = input._keras_shape[2] / residual._keras_shape[2]\n",
    "    stride_height = input._keras_shape[3] / residual._keras_shape[3]\n",
    "    equal_channels = residual._keras_shape[1] == input._keras_shape[1]\n",
    "\n",
    "    shortcut = input\n",
    "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
    "        shortcut = Convolution2D(nb_filter=residual._keras_shape[1], nb_row=1, nb_col=1,\n",
    "                                 subsample=(stride_width, stride_height),\n",
    "                                 init=\"he_normal\", border_mode=\"valid\", W_regularizer=l2(weight_decay))(input)\n",
    "        shortcut = Activation(\"relu\")(shortcut)\n",
    "\n",
    "    M1 = merge([shortcut, residual], mode=\"sum\")\n",
    "    M1 = Activation(\"relu\")(M1)\n",
    "    \n",
    "    gate = K.variable(0.0, dtype=\"uint8\")\n",
    "    decay_rate = 1\n",
    "    name = 'residual_'+str(len(gates)+1)\n",
    "    gates[name]=[decay_rate, gate]\n",
    "    return Lambda(lambda outputs: K.switch(gate, outputs[0], outputs[1]),\n",
    "                  output_shape= lambda x: x[0], name=name)([shortcut, M1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet\n",
    "\n",
    "Residual Network with depth 110 is built with basic blocks define above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://arxiv.org/pdf/1512.03385v1.pdf\n",
    "# 110 Layer resnet\n",
    "def resnet():\n",
    "    input = Input(shape=(img_channels, img_rows, img_cols))\n",
    "\n",
    "    conv1 = conv_bn_relu(input, nb_filter=16, nb_row=3, nb_col=3, W_regularizer=l2(weight_decay))\n",
    "\n",
    "    # Build residual blocks..\n",
    "    block_fn = _bottleneck\n",
    "    block1 = residual_block(conv1, block_fn, nb_filters=16, repetations=18, is_first_layer=True)\n",
    "    block2 = residual_block(block1, block_fn, nb_filters=32, repetations=18)\n",
    "    block3 = residual_block(block2, block_fn, nb_filters=64, repetations=18, subsample=True)\n",
    "    \n",
    "    # Classifier block\n",
    "    pool2 = AveragePooling2D(pool_size=(8, 8))(block3)\n",
    "    flatten1 = Flatten()(pool2)\n",
    "    final = Dense(output_dim=10, init=\"he_normal\", activation=\"softmax\", W_regularizer=l2(weight_decay))(flatten1)\n",
    "\n",
    "    model = Model(input=input, output=final)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callback and Linear Decay\n",
    "\n",
    "**set_decay_rate**: This function sets decay rate of a gate in linear fashion.\n",
    "\n",
    "\n",
    "**scheduler**: Function used to change learning rate after 25% and 50% of total epochs are done.\n",
    "\n",
    "\n",
    "**Gates_Callback**: Callback to change the state of gates after every batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def set_decay_rate():\n",
    "    for index, key in enumerate(gates):\n",
    "        gates[key][0] = 1.0 - float(index)*pL / len(gates)\n",
    "\n",
    "# Callbacks for updating gates and learning rate\n",
    "def scheduler(epoch):\n",
    "    if epoch < nb_epochs/4:\n",
    "        return learning_rate\n",
    "    elif epoch < nb_epochs/2:\n",
    "        return learning_rate*0.1\n",
    "    return learning_rate*0.01\n",
    "\n",
    "\n",
    "class Gates_Callback(Callback):\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        num = 0\n",
    "        probs = np.random.uniform(size=len(gates))\n",
    "        for i,j in zip(gates, probs):\n",
    "            if j > gates[i][0]:\n",
    "                num = num + 1\n",
    "                K.set_value(gates[i][1], 1)\n",
    "            else:\n",
    "                K.set_value(gates[i][1], 0)\n",
    "        print num\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        for i in gates:\n",
    "            K.set_value(gates[i][1],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gates=collections.OrderedDict()\n",
    "model = resnet()\n",
    "set_decay_rate()\n",
    "model.compile(optimizer=\"adadelta\", loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Network\n",
    "Didnt run this snippet because the network is too big for a webpage, can be used for debugging purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Network\n",
    "Training the network with previously coded Callbacks :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(img_gen.flow(X_train, Y_train, batch_size=batch_size, shuffle=True),\n",
    "                    samples_per_epoch=len(X_train),\n",
    "                    nb_epoch=nb_epochs,\n",
    "                    callbacks=[Gates_Callback(), LearningRateScheduler(scheduler)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
